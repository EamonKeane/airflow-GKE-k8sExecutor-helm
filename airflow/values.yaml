# Airflow RBAC service account is installed here, 
# so ensure that this is changed if using a different namespace
namespace: default

google: 
  project: 
  region: 
  databaseInstance: airflow
  databaseName: airflow

createWorkerRBAC: true
installPostgresService: true
installCloudsqlProxyDeploy: true

logVolume:
  nfsServer: "10.0.0.2"
  nfsPath: /airflow
  # e.g dags stored at /airflow/dags
  logSubPath: logs
  # This must be the same of smaller than the size of the PV you created
  size: 10Gi
  installPV: true
  installPVC: true

dagVolume:
  # Create a singe node NFS filer on Google Cloud Launcher:
  # https://cloud.google.com/launcher/docs/single-node-fileserver
  # Alternatively create a filestore:
  # https://cloud.google.com/filestore/docs/quickstart-gcloud
  # gcloud beta filestore instances create $CLOUD_FILESTORE_NAME \
  #   --project=$PROJECT \
  #   --location=$CLOUD_FILESTORE_LOCATION \
  #   --tier=$CLOUD_FILESTORE_TIER \
  #   --file-share=name=$CLOUD_FILESTORE_SHARE_NAME,capacity=$CLOUD_FILESTORE_CAPACITY \
  #   --network=name=$CLOUD_FILESTORE_NETWORK,reserved-ip-range=$CLOUD_FILESTORE_RESERVED_IP
  nfsServer: "10.0.0.2"
  nfsPath: /airflow
  # e.g dags stored at /airflow/dags
  dagSubPath: dags
  # This must be the same of smaller than the size of the PV you created
  size: 10Gi
  installPV: true
  installPVC: true
  

#### If not using the install script, create the secret below using the following form:
# kubectl create secret generic airflow \
#     --from-literal=fernet-key=$FERNET_KEY \
#     --from-literal=airflow-postgres-instance=$PROJECT:$REGION:$DATABASE_INSTANCE_NAME:$AIRFLOW_DATABASE_NAME \
#     --from-literal=sql_alchemy_conn=$SQL_ALCHEMY_CONN \
#     --from-file=$CLOUDSQL_SERVICE_ACCOUNT.json=$CLOUDSQL_SERVICE_ACCOUNT.json \
#     --from-file=kubeconfig=$KUBERNETES_KUBECONFIG_SECRET \
#     --from-literal=gcs-log-folder=gs://$GOOGLE_LOG_STORAGE_BUCKET/

secrets:
  name: airflow
  key:
    # Generate from the cryptography package
    # FERNET_KEY=$(python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())")
    fernetKey: fernet-key
    # In the format: 
    # postgresql+psycopg2://$POSTGRES_USER:$POSTGRES_PASSWORD@$POSTGRES_HOST:$POSTGRES_PORT/$POSTGRES_DB
    sqlAlchemyConn: sql_alchemy_conn
    # Kubeconfig mounted on the scheduler only. Needed for launching pods 
    # with the Kubernetes Pod Operator. This needs to be in the legacy certificate format
    # (enable legacy-authorisation if using GKE, and enable the setting on the client)
    kubeconfig: kubeconfig
    cloudSqlCredentials: airflowcloudsql.json
    gcsLogFolder: "gcs-log-folder"

airflowCfg:
  core:
    dagsFolder: /usr/local/airflow/dags
    remoteLogging: False
    remoteLogConnId: google_cloud_default
    executor: KubernetesExecutor
    parallelism: 32
    dagConcurrency: 16
  scheduler:
    schedulerHeartbeatSec: 5
    maxThreads: 2
  kubernetes:
    workerServiceAccountName: airflow-rbac
    deleteWorkerPods: True
    # This should be the same as the webScheduler.airflowCfgConfigMap unless 
    # you are creating a second configmap. 
    # There is currently only one templated (airflow-cfg-configmap.yaml). 
    # This is named {{ .Values.webScheduler.airflowCfgConfigMap }}
    airflowConfigmap: airflow-configmap
    workerContainerRepository: quay.io/eamonkeane/airflow-k8s
    workerContainerTag: "0.2"
    namespace: default
    # Add a list of secrets in the form of ENV_VARIABLE=KUBERNETES_SECRET_NAME=KUBERNETES_SECRET_KEY
    # This is injected into the environment of the Kubernetes Executor workers
  kubernetesSecrets: |-
    SQL_ALCHEMY_CONN=airflow=sql_alchemy_conn
    AIRFLOW__CORE__FERNET_KEY=airflow=fernet-key
    AIRFLOW__CORE__REMOTE_BASE_LOG_FOLDER=airflow=gcs-log-folder
    # Add a list of key value pairs for node labels you want the Kubernetes Exeuctor workers
    # To be scheduled on. You can do this by using the kubectl label nodes
    # https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
  # If you have created a second pool for workers, put the node labels here
  kubernetesNodeSelectors: |-
    airflow=airflow_workers
    pool=preemptible


# This section contains values for the pre-install hook, the web and the scheduler deployments
webScheduler:
  # Ensure the label is applied to the leader nodes (kubectl label airflow-leader)
  # $NODE_NAME=gke-airflow-default-pool-e573c3f7-nhx4
  # e.g.kubectl label node $NODE_NAME app=airflow-leader
  nodeSelector:
    # app: airflow-leader
  web:
    name: web
    resources:
      limits:
        cpu: 1000m
        memory: 1Gi
      requests:
        cpu: 1000m
        memory: 1Gi
    # If setting authenticate to true, create a secret of the form:
    # kubectl create secret generic google-oauth \
    #     --from-literal=client_id=$CLIENT_ID \
    #     --from-literal=client_secret=$CLIENT_SECRET 
    authenticate: False
    ## These values are only needed if authenticate is set to true
    authBackend: airflow.contrib.auth.backends.google_auth
    googleAuthDomain: mysite.io
    googleAuthSecret: google-oauth
    googleAuthSecretClientIDKey: client_id
    googleAuthSecretClientSecretKey: client_secret
    ##
    dagVolumeReadOnly: True
    replicaCount: 1
    service:
      type: ClusterIP
      port: 8080
  scheduler:
    name: scheduler
    resources:
      limits:
        cpu: 1000m
        memory: 1Gi
      requests:
        cpu: 1000m
        memory: 1Gi
    dagVolumeReadOnly: False
    serviceAccountName: airflow-rbac
    kubeconfigMountPath: /root/airflow/kubeconfig
  preHook:
    # This performs the migrations and runs before any new deployment or upgrade
    install: true
    args: "airflow initdb && alembic upgrade heads"
  installWebServer: true
  installScheduler: true
  image: quay.io/eamonkeane/airflow-k8s
  tag: "0.2"
  imagePullPolicy: IfNotPresent
  dagsVolumeClaim: airflow-dags
  logsVolumeClaim: airflow-logs
  dagsMountPath: /usr/local/airflow/dags
  logsMountPath: /usr/local/airflow/logs
  dagsVolumeClaimSubPath:
  airflowCfgPath: /usr/local/airflow/airflow.cfg
  airflowCfgConfigMap: airflow-configmap

ingress:
  enabled: false
  annotations:
    # Install nginx-ingress to have this annotation create an ingress
    # https://hub.kubeapps.com/charts/stable/nginx-ingress
    kubernetes.io/ingress.class: "nginx"
    kubernetes.io/tls-acme: "true"
    # Use cert-manager to automatically provision acme certs
    # https://hub.kubeapps.com/charts/stable/cert-manager
    # This ensures that a user gets directed to the same webserver pod if using multiple
    # webserver pods during a session.
    # https://github.com/kubernetes/ingress-nginx/tree/master/docs/examples/affinity/cookie
    nginx.ingress.kubernetes.io/affinity: "cookie"
    nginx.ingress.kubernetes.io/session-cookie-name: "route"
    nginx.ingress.kubernetes.io/session-cookie-hash: "sha1"
  path: ""
  hosts: 
    - airflow.mysite.io
  tls:
  - hosts:
    - airflow.mysite.io
    secretName: airflow.mysite.io
